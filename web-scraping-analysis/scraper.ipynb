{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.inskysolutions.com/'\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if response.status_code == 200:\n",
    "if response.ok:\n",
    "    html = response.content\n",
    "    print(html[:100])\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CILJ\n",
    "- dobiti što više tekstova \n",
    "    - zanimaju nas svi opisni tekstovi (o pojedinim produktima, o tvrtki, o integracijama, rješenjima itd...)\n",
    "\n",
    "### KAKO \n",
    "- S dev toolsima inspectamo glavnu stranicu i tražimo najbolji način za doći do tekstova\n",
    "    - tražimo linkove za druge pageve gdje ima više teksta\n",
    "    - pogledajte da već nakon prvih par divova unutar <form name> možemo doći do nav bara koji ima id='navigation'!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navigation = soup.find_all('nav', id='navigation')\n",
    "print(type(navigation))\n",
    "print(len(navigation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ono što sada možemo je iterirati kroz bs4.element.ResultSet kao što iteriramo kroz listu \n",
    "# https://stackoverflow.com/questions/36076052/beautifulsoup-find-all-on-bs4-element-resultset-object-or-list\n",
    "\n",
    "buttons = []\n",
    "for element in navigation:\n",
    "    buttons.append(element.find_all('a')) # <class 'bs4.element.Tag'>\n",
    "    # print(nav_button.text)\n",
    "print(buttons)\n",
    "print(len(buttons))\n",
    "print(len(buttons[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sad vidimo da možemo izvući linkove iz gornje liste\n",
    "### ali nam ne trebaju svi nego samo oni koji imaju neki \"tekst\" (ima puno praznih 'a' elemenata) po hrefom\n",
    "### to nije isto kao i .text jer bismo s tekstom dobili ono što je pod TITLE\n",
    "\n",
    "# https://stackoverflow.com/questions/57395509/get-item-from-bs4-element-tag\n",
    "# https://www.crummy.com/software/BeautifulSoup/bs4/doc/#tag\n",
    "\n",
    "linkovi = []\n",
    "kategorije = []\n",
    "for element in navigation:\n",
    "    tags = element.find_all('a') \n",
    "    for tag in tags:\n",
    "        link = tag.get('href')\n",
    "        ### sad imamo stringove koji predstavljaju linkove na druge 'pages' na ovoj web stranici\n",
    "        ### s obzirom da su neki 'anchori' na main pageu, njih zaobilazimo\n",
    "        # print(tag.text)\n",
    "        if link != '#':\n",
    "            linkovi.append(link)\n",
    "            kategorije.append(tag.text)\n",
    "        \n",
    "print(kategorije)\n",
    "print(linkovi)\n",
    "print(len(linkovi))\n",
    "\n",
    "assert len(linkovi) == len(kategorije)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INSPECTAMO JOŠ JEDAN PAGE OD OVIH ČIJE SMO LINKOVE SADA IZGENERIRALI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### svi tekstovi se nalaze u divovima unutar <main id='pageContainer'> elementa\n",
    "### ponavljamo sve ispočetka \n",
    "    ### primijetite kako bi se ovaj proces sada trebao pretvoriti u funkcije jer se ponavljamo :) \n",
    "page_url = 'https://www.inskysolutions.com/tourisminsky.aspx'\n",
    "response = requests.get(page_url)\n",
    "if response.ok:\n",
    "    html = response.content\n",
    "    print(html[:100])\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "divs = soup.body.form.main.find_all('div')\n",
    "print(len(divs))\n",
    "\n",
    "articles = [div.find('article') for div in divs]\n",
    "print(len(articles))\n",
    "\n",
    "paragraphs = []\n",
    "for element in articles:\n",
    "    if element is not None:\n",
    "        # print(type(element)) \n",
    "        # ako je tag, možemo pozivati sve atribute koje vidimo na https://www.crummy.com/software/BeautifulSoup/bs4/doc/#tag\n",
    "\n",
    "        ### ako želimo, možemo spremiti ove tekstove ili možemo raditi dodatne filtere s obzirom na elemente, id-eve ili klase\n",
    "        # print(element.text)\n",
    "        paragraphs.append(element.text.strip())\n",
    "print(len(paragraphs))\n",
    "print(paragraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PRETPOSTAVKA\n",
    "- trebalo bi biti dovoljno 'inspectati' jedan page, a drugi bi trebali imati istu strukturu\n",
    "- ako složimo url-ove pomoću glavnog i svih linkova iz napravljene liste, možemo kroz petlju iterirati i izbaciti van željene tekstove/podatke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### koji modul možemo koristiti za spajanje putanja? :) \n",
    "### odmah možete vidjeti i zašto to nije najbolja opcija - https://stackoverflow.com/questions/1793261/how-to-join-components-of-a-path-when-you-are-constructing-a-url-in-python\n",
    "base_url = 'https://www.inskysolutions.com/'\n",
    "for l in linkovi:\n",
    "    link = os.path.join(base_url,l[1:])\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_texts = []\n",
    "urls = []\n",
    "\n",
    "base_url = 'https://www.inskysolutions.com/'\n",
    "for l in linkovi:\n",
    "    link = os.path.join(base_url,l[1:])\n",
    "    urls.append(link)\n",
    "\n",
    "    response = requests.get(link)\n",
    "    if response.ok:\n",
    "        html = response.content\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        ### ako dobijem error, želim da mi kod samo preskoči taj cijeli soup object/trenutnu stranicu\n",
    "        ### https://stackoverflow.com/questions/19522990/python-catch-exception-and-continue-try-block\n",
    "        ### ovo je loša praksa, inače, jer ako već hvatate neke errore/exceptione, onda bi bilo oke znati što je to :)\n",
    "        try:\n",
    "            divs = soup.body.form.main.find_all('div')\n",
    "\n",
    "            articles = [div.find('article') for div in divs]\n",
    "            # print(len(articles))\n",
    "\n",
    "            paragraphs = []\n",
    "            for element in articles:\n",
    "                if element is not None:\n",
    "                    # print(type(element)) \n",
    "                    # ako je tag, možemo pozivati sve atribute koje vidimo na https://www.crummy.com/software/BeautifulSoup/bs4/doc/#tag\n",
    "\n",
    "                    ### ako želimo, možemo spremiti ove tekstove ili možemo raditi dodatne filtere s obzirom na elemente, id-eve ili klase\n",
    "                    # print(element.text)\n",
    "                    paragraphs.append(element.text.strip())\n",
    "            # print(len(paragraphs))\n",
    "            # print(paragraphs)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "    page_texts.append(paragraphs)\n",
    "print(len(page_texts))\n",
    "# print(page_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(page_texts) == len(kategorije)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dovoljno dobro? \n",
    "...\n",
    "\n",
    "\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### saveamo naše liste u csv file koji onda dalje možemo \"exploreati\"\n",
    "\n",
    "import csv\n",
    "csv_filename = 'data_v1.csv'\n",
    "\n",
    "rows = zip(kategorije, urls, page_texts)\n",
    "if not os.path.isfile(os.path.join(os.getcwd(), csv_filename)):\n",
    "    with open(os.path.join(os.getcwd(), csv_filename), \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        for row in rows:\n",
    "            writer.writerow(row)\n",
    "else:\n",
    "    print(\"the file already exists!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59f3795f81c12f59836a85374165337db15fbfd2df129378202aa0348298c8ca"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('web-scraping-env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
